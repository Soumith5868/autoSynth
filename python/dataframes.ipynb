{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fc00af",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m base_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize OpenAI-compatible client\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig loaded from .env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/_client.py:126\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    124\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read values\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# Initialize OpenAI-compatible client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(\"Config loaded from .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /app\n",
      "Files here: ['.dockerignore', '.env', '.git', '.gitignore', '.ipynb_checkpoints', 'config.yaml', 'docker-compose.yaml', 'Dockerfile', 'python', 'README.md', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"Files here:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"schema_models\", \"/app/python/schema_models.py\")\n",
    "schema_models = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(schema_models)\n",
    "\n",
    "SchemaPrompt = schema_models.SchemaPrompt\n",
    "SchemaObject = schema_models.SchemaObject\n",
    "ColumnSchema = schema_models.ColumnSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b46e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pydantic import ValidationError\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "def test_llm(client):\n",
    "    test = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say hello\"}]\n",
    "    )\n",
    "    print(\"✅ Test LLM response:\", test.choices[0].message.content)\n",
    "\n",
    "\n",
    "class SchemaAgent:\n",
    "    def __init__(self, llm_client: OpenAI):\n",
    "        self.llm = llm_client\n",
    "\n",
    "    def generate_from_prompt(self, schema_prompt: SchemaPrompt) -> SchemaObject:\n",
    "        assert schema_prompt.prompt, \"Prompt is required\"\n",
    "        system_msg = (\n",
    "            \"You are a strict schema generator. Return ONLY a JSON object like:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"columns\\\": [\\n\"\n",
    "            \"    {\\\"name\\\": \\\"age\\\", \\\"type\\\": \\\"int\\\", \\\"min\\\": 0, \\\"max\\\": 120},\\n\"\n",
    "            \"    {\\\"name\\\": \\\"gender\\\", \\\"type\\\": \\\"categorical\\\", \\\"values\\\": [\\\"M\\\", \\\"F\\\"]},\\n\"\n",
    "            \"    {\\\"name\\\": \\\"admission_date\\\", \\\"type\\\": \\\"datetime\\\", \\\"format\\\": \\\"%Y-%m-%d\\\"}\\n\"\n",
    "            \"  ]\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "        user_msg = f\"Use-case: {schema_prompt.use_case}\\nPrompt: {schema_prompt.prompt}\"\n",
    "\n",
    "        response = self.llm.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        text = response.choices[0].message.content\n",
    "        if not text or not text.strip():\n",
    "            raise ValueError(\"❌ Empty response from LLM. Check API key, base URL, or network.\")\n",
    "        print(\"✅ LLM Output:\\n\", text)\n",
    "        if not text or not text.strip():\n",
    "            raise ValueError(\"LLM response is empty or invalid. Check API status or quota.\")\n",
    "\n",
    "        try:\n",
    "            # Try to extract valid JSON from potentially messy output\n",
    "            json_start = text.find('{')\n",
    "            json_end = text.rfind('}') + 1\n",
    "            parsed = json.loads(text[json_start:json_end])\n",
    "            return SchemaObject(use_case=schema_prompt.use_case, **parsed)\n",
    "        except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"❌ LLM output invalid: {e}\")\n",
    "            raise ValueError(f\"LLM returned malformed or invalid schema.\\nRaw output:\\n{text}\")\n",
    "\n",
    "    def generate_from_csv(self, schema_prompt: SchemaPrompt) -> SchemaObject:\n",
    "        assert schema_prompt.csv_path, \"CSV path is required\"\n",
    "        df = pd.read_csv(schema_prompt.csv_path)\n",
    "        cols = []\n",
    "\n",
    "        for col in df.columns:\n",
    "            dtype = df[col].dtype\n",
    "            col_type = \"string\"\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                col_type = \"int\"\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                col_type = \"float\"\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                col_type = \"datetime\"\n",
    "            elif pd.api.types.is_categorical_dtype(dtype) or df[col].nunique() < 10:\n",
    "                col_type = \"categorical\"\n",
    "\n",
    "            col_schema = ColumnSchema(\n",
    "                name=col,\n",
    "                type=col_type,\n",
    "                min=float(df[col].min()) if col_type in [\"int\", \"float\"] else None,\n",
    "                max=float(df[col].max()) if col_type in [\"int\", \"float\"] else None,\n",
    "                values=list(map(str, df[col].dropna().unique())) if col_type == \"categorical\" else None,\n",
    "                format=\"%Y-%m-%d\" if col_type == \"datetime\" else None\n",
    "            )\n",
    "            cols.append(col_schema)\n",
    "\n",
    "        return SchemaObject(use_case=schema_prompt.use_case, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f1906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Output:\n",
      " ```json\n",
      "{\n",
      "  \"columns\": [\n",
      "    {\"name\": \"age\", \"type\": \"int\", \"min\": 18, \"max\": 65},\n",
      "    {\"name\": \"gender\", \"type\": \"categorical\", \"values\": [\"M\", \"F\"]},\n",
      "    {\"name\": \"role\", \"type\": \"string\"},\n",
      "    {\"name\": \"join_date\", \"type\": \"datetime\", \"format\": \"%Y-%m-%d\"}\n",
      "  ]\n",
      "}\n",
      "```\n",
      "use_case='Employee record generation' columns=[ColumnSchema(name='age', type='int', min=18.0, max=65.0, format=None, values=None), ColumnSchema(name='gender', type='categorical', min=None, max=None, format=None, values=['M', 'F']), ColumnSchema(name='role', type='string', min=None, max=None, format=None, values=None), ColumnSchema(name='join_date', type='datetime', min=None, max=None, format='%Y-%m-%d', values=None)]\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = SchemaPrompt(\n",
    "    use_case=\"Employee record generation\",\n",
    "    prompt=\"Generate a schema for employee records including age (18-65), gender (M/F), role, and join date\"\n",
    ")\n",
    "\n",
    "schema_agent = SchemaAgent(llm_client=client)  # `client` = your DeepSeek OpenAI-compatible instance\n",
    "\n",
    "schema = schema_agent.generate_from_prompt(schema_prompt)\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ctgan\n",
      "  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/site-packages (from ctgan) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/site-packages (from ctgan) (2.3.0)\n",
      "Collecting torch>=1.13.0 (from ctgan)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.10/site-packages (from ctgan) (4.67.1)\n",
      "Collecting rdt>=1.14.0 (from ctgan)\n",
      "  Downloading rdt-1.17.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->ctgan) (1.17.0)\n",
      "Collecting scipy>=1.9.2 (from rdt>=1.14.0->ctgan)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from rdt>=1.14.0->ctgan)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.10/site-packages (from rdt>=1.14.0->ctgan) (37.3.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.1.0->rdt>=1.14.0->ctgan)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->rdt>=1.14.0->ctgan)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch>=1.13.0->ctgan)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->ctgan) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.13.0->ctgan)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.13.0->ctgan)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->ctgan) (3.1.6)\n",
      "Collecting fsspec (from torch>=1.13.0->ctgan)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.13.0->ctgan)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.13.0->ctgan) (65.5.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.13.0->ctgan)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->ctgan) (3.0.2)\n",
      "Downloading ctgan-0.11.0-py3-none-any.whl (24 kB)\n",
      "Downloading rdt-1.17.0-py3-none-any.whl (73 kB)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, fsspec, filelock, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, rdt, nvidia-cusolver-cu12, torch, ctgan\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [ctgan]m25/27\u001b[0m [torch]-cusolver-cu12]2]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ctgan-0.11.0 filelock-3.18.0 fsspec-2025.5.1 joblib-1.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 rdt-1.17.0 scikit-learn-1.7.0 scipy-1.15.3 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ctgan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from typing import List\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "class CTGANGeneratorAgent:\n",
    "    def __init__(self):\n",
    "        self.faker = Faker()\n",
    "        self.model = CTGAN(epochs=100)\n",
    "        self.generated_categories = {}\n",
    "\n",
    "    def get_dynamic_category(self, col_name: str, generator_fn, max_unique=200):\n",
    "        if col_name not in self.generated_categories:\n",
    "            self.generated_categories[col_name] = list({generator_fn() for _ in range(max_unique)})\n",
    "        return random.choice(self.generated_categories[col_name])\n",
    "    \n",
    "    \n",
    "    def generate_fake_data_from_schema(self, schema: SchemaObject, n=100) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for _ in range(n):\n",
    "            row = {}\n",
    "            for col in schema.columns:\n",
    "                if col.type == \"int\":\n",
    "                    row[col.name] = random.randint(int(col.min or 0), int(col.max or 100))\n",
    "                elif col.type == \"float\":\n",
    "                    row[col.name] = round(random.uniform(col.min or 0.0, col.max or 100.0), 2)\n",
    "                elif col.type == \"categorical\":\n",
    "                    row[col.name] = random.choice(col.values or [\"Unknown\"])\n",
    "                elif col.type == \"datetime\":\n",
    "                    fmt = col.format or \"%Y-%m-%d\"\n",
    "                    row[col.name] = self.faker.date_between(start_date='-5y', end_date='today').strftime(fmt)\n",
    "                elif col.type == \"string\":\n",
    "                    row[col.name] = None\n",
    "                else:\n",
    "                    row[col.name] = None\n",
    "            rows.append(row)\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def fit_ctgan_on_fake_data(self, fake_df: pd.DataFrame, schema: SchemaObject):\n",
    "        cat_cols = [col.name for col in schema.columns if col.type == \"categorical\"]\n",
    "        self.model.fit(fake_df, discrete_columns=cat_cols)\n",
    "\n",
    "    def sample(self, n=100) -> pd.DataFrame:\n",
    "        return self.model.sample(n)\n",
    "\n",
    "    def generate_from_schema(self, schema: SchemaObject, n=100) -> pd.DataFrame:\n",
    "        fake_df = self.generate_fake_data_from_schema(schema, n=100)\n",
    "\n",
    "        valid_types = [\"int\", \"float\", \"categorical\"]\n",
    "        safe_cols = [col.name for col in schema.columns if col.type in valid_types]\n",
    "        fake_df = fake_df[safe_cols]\n",
    "\n",
    "        self.fit_ctgan_on_fake_data(fake_df, schema)\n",
    "        sampled = self.sample(n)\n",
    "        return self.enforce_bounds(sampled, schema)\n",
    "    \n",
    "    def enforce_bounds(self, df: pd.DataFrame, schema: SchemaObject) -> pd.DataFrame:\n",
    "        for col in schema.columns:\n",
    "            if col.type == \"int\":\n",
    "                df[col.name] = df[col.name].clip(lower=col.min or 0, upper=col.max or 100).astype(int)\n",
    "            elif col.type == \"float\":\n",
    "                df[col.name] = df[col.name].clip(lower=col.min or 0.0, upper=col.max or 100.0).astype(float)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414586f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Output:\n",
      " ```json\n",
      "{\n",
      "  \"columns\": [\n",
      "    {\"name\": \"name\", \"type\": \"string\"},\n",
      "    {\"name\": \"place\", \"type\": \"string\"},\n",
      "    {\"name\": \"age\", \"type\": \"int\", \"min\": 18, \"max\": 60},\n",
      "    {\"name\": \"gender\", \"type\": \"categorical\", \"values\": [\"M\", \"F\"]},\n",
      "    {\"name\": \"city\", \"type\": \"string\"},\n",
      "    {\"name\": \"salary\", \"type\": \"int\", \"min\": 100000, \"max\": 200000},\n",
      "    {\"name\": \"join_date\", \"type\": \"datetime\", \"format\": \"%Y-%m-%d\"}\n",
      "  ]\n",
      "}\n",
      "```\n",
      "   age gender  salary\n",
      "0   36      F  116898\n",
      "1   30      M  100000\n",
      "2   36      F  155347\n",
      "3   25      F  150042\n",
      "4   18      F  118637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "schema_prompt = SchemaPrompt(\n",
    "    use_case=\"Retail customer data\",\n",
    "    prompt=\"Create schema with name,place ,age (18-60), gender (M/F), city, salary (100k-200k), join_date\"\n",
    ")\n",
    "\n",
    "schema = SchemaAgent(llm_client=client).generate_from_prompt(schema_prompt)\n",
    "\n",
    "gen = CTGANGeneratorAgent()\n",
    "df = gen.generate_from_schema(schema, n=5)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4642adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90eae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 163896 names\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "fn_txt_path = Path(\"/app/dataset/first_names.txt\")\n",
    "\n",
    "with open(fn_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    first_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(\"✅ Loaded\", len(first_names), \"names\")\n",
    "\n",
    "json_path = \"/app/dataset/first_names.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(first_names, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59d28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 98343 names\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "ln_txt_path = Path(\"/app/dataset/last_names.txt\")\n",
    "\n",
    "with open(ln_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    last_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(\"✅ Loaded\", len(last_names), \"names\")\n",
    "\n",
    "json_path = \"/app/dataset/last_names.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(last_names, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2dc9cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mnames\u001b[49m)))\n\u001b[1;32m      2\u001b[0m char2idx \u001b[38;5;241m=\u001b[39m {ch: i \u001b[38;5;28;01mfor\u001b[39;00m i, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chars)}\n\u001b[1;32m      3\u001b[0m idx2char \u001b[38;5;241m=\u001b[39m {i: ch \u001b[38;5;28;01mfor\u001b[39;00m ch, i \u001b[38;5;129;01min\u001b[39;00m char2idx\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(\"\".join(names)))\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "VOCAB_SIZE = len(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "for name in names:\n",
    "    tokens.update(name.split())\n",
    "\n",
    "word2idx = {word: i for i, word in enumerate(sorted(tokens))}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "VOCAB_SIZE = len(word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       " [8, 16, 26, 15, 8],\n",
       " [8, 16, 26, 15, 8, 15],\n",
       " [8, 17, 8, 32],\n",
       " [8, 8, 0, 16, 26, 15, 8],\n",
       " [8, 8, 0, 16, 26, 15, 8, 15],\n",
       " [8, 8, 9, 8, 21],\n",
       " [8, 8, 9, 8, 26],\n",
       " [8, 8, 9, 15, 8],\n",
       " [8, 8, 9, 16, 8],\n",
       " [8, 8, 9, 16, 11],\n",
       " [8, 8, 9, 16, 11, 8, 15],\n",
       " [8, 8, 9, 16, 11, 8, 20, 20, 8, 25],\n",
       " [8, 8, 9, 16, 25],\n",
       " [8, 8, 9, 25, 16, 12, 19, 19, 8],\n",
       " [8, 8, 10, 15, 8, 19],\n",
       " [8, 8, 11],\n",
       " [8, 8, 11, 8],\n",
       " [8, 8, 11, 8, 20],\n",
       " [8, 8, 11, 8, 21],\n",
       " [8, 8, 11, 8, 25, 26, 15],\n",
       " [8, 8, 11, 8, 32, 8],\n",
       " [8, 8, 11, 12, 21],\n",
       " [8, 8, 11, 12, 26, 15],\n",
       " [8, 8, 11, 15, 8, 20],\n",
       " [8, 8, 11, 15, 8, 21],\n",
       " [8, 8, 11, 15, 8, 29],\n",
       " [8, 8, 11, 15, 8, 29, 8, 21],\n",
       " [8, 8, 11, 15, 16],\n",
       " [8, 8, 11, 15, 16, 25, 8],\n",
       " [8, 8, 11, 15, 16, 25, 8, 21],\n",
       " [8, 8, 11, 15, 16, 26, 15],\n",
       " [8, 8, 11, 15, 16, 27, 15],\n",
       " [8, 8, 11, 15, 16, 27, 15, 32, 8],\n",
       " [8, 8, 11, 15, 25, 16, 27, 15],\n",
       " [8, 8, 11, 15, 29, 16, 18],\n",
       " [8, 8, 11, 15, 29, 16, 18, 8],\n",
       " [8, 8, 11, 15, 32, 8],\n",
       " [8, 8, 11, 15, 32, 8, 21],\n",
       " [8, 8, 11, 15, 32, 8, 25, 12, 11, 11, 32],\n",
       " [8, 8, 11, 15, 32, 8, 26, 25, 16],\n",
       " [8, 8, 11, 16],\n",
       " [8, 8, 11, 16, 8, 21],\n",
       " [8, 8, 11, 16, 19],\n",
       " [8, 8, 11, 16, 19, 8],\n",
       " [8, 8, 11, 16, 19, 32, 21, 21],\n",
       " [8, 8, 11, 16, 21],\n",
       " [8, 8, 11, 16, 25, 8, 27, 15],\n",
       " [8, 8, 11, 16, 26, 15],\n",
       " [8, 8, 11, 16, 26, 15, 16, 29],\n",
       " [8, 8, 11, 16, 26, 22, 21],\n",
       " [8, 8, 11, 16, 27],\n",
       " [8, 8, 11, 16, 27, 15],\n",
       " [8, 8, 11, 16, 27, 15, 32, 8],\n",
       " [8, 8, 11, 16, 27, 16, 32, 8],\n",
       " [8, 8, 11, 16, 27, 25, 16],\n",
       " [8, 8, 11, 16, 27, 32, 8],\n",
       " [8, 8, 11, 16, 27, 32, 8, 25, 8, 20],\n",
       " [8, 8, 11, 16, 29],\n",
       " [8, 8, 11, 17, 12],\n",
       " [8, 8, 11, 20],\n",
       " [8, 8, 11, 22, 21],\n",
       " [8, 8, 11, 25, 16, 8, 21],\n",
       " [8, 8, 11, 25, 16, 18, 8],\n",
       " [8, 8, 11, 25, 16, 27],\n",
       " [8, 8, 11, 25, 16, 27, 15],\n",
       " [8, 8, 11, 25, 16, 27, 16],\n",
       " [8, 8, 11, 28],\n",
       " [8, 8, 11, 29, 16],\n",
       " [8, 8, 11, 29, 16, 18],\n",
       " [8, 8, 11, 29, 16, 18, 8],\n",
       " [8, 8, 11, 32, 8],\n",
       " [8, 8, 11, 32, 8, 21],\n",
       " [8, 8, 11, 32, 8, 21, 27],\n",
       " [8, 8, 11, 32, 8, 21, 27, 15],\n",
       " [8, 8, 11, 32, 21],\n",
       " [8, 8, 12, 12, 11, 8, 15],\n",
       " [8, 8, 12, 12, 26, 15, 8],\n",
       " [8, 8, 12, 19, 19, 8],\n",
       " [8, 8, 12, 25, 32, 21],\n",
       " [8, 8, 13],\n",
       " [8, 8, 13, 16],\n",
       " [8, 8, 13, 16, 8],\n",
       " [8, 8, 13, 16, 32, 8],\n",
       " [8, 8, 13, 16, 32, 8, 15],\n",
       " [8, 8, 13, 18, 12],\n",
       " [8, 8, 13, 18, 12, 8],\n",
       " [8, 8, 13, 18, 22],\n",
       " [8, 8, 13, 25, 12, 12, 21],\n",
       " [8, 8, 13, 25, 16, 21],\n",
       " [8, 8, 13, 27, 8, 9],\n",
       " [8, 8, 14, 8, 20],\n",
       " [8, 8, 14, 8, 21, 11],\n",
       " [8, 8, 14, 8, 27],\n",
       " [8, 8, 14, 12],\n",
       " [8, 8, 14, 17, 12],\n",
       " [8, 8, 14, 20, 8, 21],\n",
       " [8, 8, 14, 21, 8],\n",
       " [8, 8, 14, 22, 27],\n",
       " [8, 8, 14, 22, 27, 15],\n",
       " [8, 8, 15, 8, 8, 21],\n",
       " [8, 8, 15, 8, 11],\n",
       " [8, 8, 15, 8, 21],\n",
       " [8, 8, 15, 8, 21, 8],\n",
       " [8, 8, 15, 12, 19, 16],\n",
       " [8, 8, 15, 16, 19],\n",
       " [8, 8, 15, 16, 19, 28, 11, 11, 16, 21],\n",
       " [8, 8, 15, 16, 20],\n",
       " [8, 8, 15, 16, 25],\n",
       " [8, 8, 15, 19, 16, 32, 8, 15],\n",
       " [8, 8, 15, 21, 8],\n",
       " [8, 8, 15, 25, 22, 21],\n",
       " [8, 8, 15, 32, 8, 21],\n",
       " [8, 8, 16, 11, 8, 15],\n",
       " [8, 8, 16, 11, 8, 21],\n",
       " [8, 8, 16, 11, 12, 21],\n",
       " [8, 8, 16, 11, 32, 21],\n",
       " [8, 8, 16, 19, 8],\n",
       " [8, 8, 16, 19, 16, 32, 8, 15],\n",
       " [8, 8, 16, 19, 32, 8, 15],\n",
       " [8, 8, 16, 20, 8],\n",
       " [8, 8, 16, 21, 8],\n",
       " [8, 8, 16, 25, 8],\n",
       " [8, 8, 16, 25, 8, 15],\n",
       " [8, 8, 16, 26, 15, 8],\n",
       " [8, 8, 16, 26, 15, 8, 15],\n",
       " [8, 8, 16, 32, 8, 21, 8],\n",
       " [8, 8, 16, 33, 8],\n",
       " [8, 8, 16, 33, 8, 15],\n",
       " [8, 8, 17, 8],\n",
       " [8, 8, 17, 8, 15],\n",
       " [8, 8, 17, 8, 32, 19, 8, 15],\n",
       " [8, 8, 17, 16, 29],\n",
       " [8, 8, 17, 22, 21],\n",
       " [8, 8, 18, 8, 21, 18, 26, 15, 8],\n",
       " [8, 8, 18, 8, 25, 26, 15],\n",
       " [8, 8, 18, 8, 26],\n",
       " [8, 8, 18, 8, 26, 15],\n",
       " [8, 8, 18, 12, 12, 20],\n",
       " [8, 8, 18, 16, 13],\n",
       " [8, 8, 18, 16, 13, 8],\n",
       " [8, 8, 18, 16, 13, 8, 15],\n",
       " [8, 8, 18, 16, 19],\n",
       " [8, 8, 18, 16, 19, 8, 15],\n",
       " [8, 8, 18, 16, 21],\n",
       " [8, 8, 18, 16, 25, 8],\n",
       " [8, 8, 18, 16, 32, 8, 15],\n",
       " [8, 8, 18, 25, 16, 27, 16],\n",
       " [8, 8, 18, 25, 28, 27, 16],\n",
       " [8, 8, 19, 8],\n",
       " [8, 8, 19, 8, 8],\n",
       " [8, 8, 19, 8, 16, 32, 8],\n",
       " [8, 8, 19, 8, 16, 32, 8, 15],\n",
       " [8, 8, 19, 8, 20],\n",
       " [8, 8, 19, 8, 21, 8],\n",
       " [8, 8, 19, 8, 21, 8, 15],\n",
       " [8, 8, 19, 8, 21, 16],\n",
       " [8, 8, 19, 8, 23],\n",
       " [8, 8, 19, 8, 26, 16, 8],\n",
       " [8, 8, 19, 8, 32, 8],\n",
       " [8, 8, 19, 8, 32, 8, 15],\n",
       " [8, 8, 19, 8, 32, 16, 8, 15],\n",
       " [8, 8, 19, 8, 32, 17, 8, 15],\n",
       " [8, 8, 19, 8, 32, 21, 8],\n",
       " [8, 8, 19, 8, 32, 26, 15, 8],\n",
       " [8, 8, 19, 8, 32, 26, 16, 8],\n",
       " [8, 8, 19, 9, 12, 25, 27],\n",
       " [8, 8, 19, 11, 12, 25, 16, 10, 15],\n",
       " [8, 8, 19, 11, 12, 25, 18],\n",
       " [8, 8, 19, 11, 25, 16, 18],\n",
       " [8, 8, 19, 12],\n",
       " [8, 8, 19, 12, 8],\n",
       " [8, 8, 19, 12, 8, 15],\n",
       " [8, 8, 19, 12, 8, 15, 32, 8],\n",
       " [8, 8, 19, 12, 8, 32, 8, 15],\n",
       " [8, 8, 19, 12, 12, 21],\n",
       " [8, 8, 19, 12, 12, 21, 8],\n",
       " [8, 8, 19, 12, 12, 32, 8],\n",
       " [8, 8, 19, 12, 12, 32, 8, 15],\n",
       " [8, 8, 19, 12, 16, 8],\n",
       " [8, 8, 19, 12, 16, 8, 15],\n",
       " [8, 8, 19, 12, 16, 14, 15, 8],\n",
       " [8, 8, 19, 12, 16, 32, 8],\n",
       " [8, 8, 19, 12, 16, 32, 8, 15],\n",
       " [8, 8, 19, 12, 21, 8],\n",
       " [8, 8, 19, 12, 31, 16, 26],\n",
       " [8, 8, 19, 12, 31, 28, 26],\n",
       " [8, 8, 19, 12, 32, 8],\n",
       " [8, 8, 19, 12, 32, 8, 15],\n",
       " [8, 8, 19, 16],\n",
       " [8, 8, 19, 16, 8],\n",
       " [8, 8, 19, 16, 8, 15],\n",
       " [8, 8, 19, 16, 8, 21, 8],\n",
       " [8, 8, 19, 16, 8, 26],\n",
       " [8, 8, 19, 16, 8, 32, 8, 15],\n",
       " [8, 8, 19, 16, 8, 32, 15],\n",
       " [8, 8, 19, 16, 10, 16, 8],\n",
       " [8, 8, 19, 16, 12, 14, 15, 8],\n",
       " [8, 8, 19, 16, 12, 32, 8, 15],\n",
       " [8, 8, 19, 16, 15, 8],\n",
       " [8, 8, 19, 16, 17, 8, 15],\n",
       " [8, 8, 19, 16, 19, 8, 15],\n",
       " [8, 8, 19, 16, 20],\n",
       " [8, 8, 19, 16, 20, 8, 15],\n",
       " [8, 8, 19, 16, 21, 8],\n",
       " [8, 8, 19, 16, 21, 8, 15],\n",
       " [8, 8, 19, 16, 26, 8],\n",
       " [8, 8, 19, 16, 26, 15],\n",
       " [8, 8, 19, 16, 26, 15, 8],\n",
       " [8, 8, 19, 16, 29, 16, 8],\n",
       " [8, 8, 19, 16, 32, 8],\n",
       " [8, 8, 19, 16, 32, 8, 8],\n",
       " [8, 8, 19, 16, 32, 8, 15],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 19, 22, 28, 16, 26, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 20, 8, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 20, 8, 25, 16, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 20, 8, 32],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 25, 22, 26, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 3, 26, 18, 32, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 8],\n",
       " [8, 8, 19, 16, 32, 8, 15, 20, 8, 25, 16, 12],\n",
       " [8, 8, 19, 16, 32, 8, 15, 25, 22, 26, 12],\n",
       " [8, 8, 19, 16, 32, 8, 21],\n",
       " [8, 8, 19, 16, 32, 8, 21, 8],\n",
       " [8, 8, 19, 16, 32, 8, 21, 21, 8],\n",
       " [8, 8, 19, 16, 32, 15, 8],\n",
       " [8, 8, 19, 16, 32, 16, 8, 15],\n",
       " [8, 8, 19, 18, 12],\n",
       " [8, 8, 19, 19, 8, 32, 8],\n",
       " [8, 8, 19, 19, 16, 32, 8, 15],\n",
       " [8, 8, 19, 19, 32, 8, 15],\n",
       " [8, 8, 19, 22, 18],\n",
       " [8, 8, 19, 22, 21],\n",
       " [8, 8, 19, 22, 21, 16],\n",
       " [8, 8, 19, 26, 27],\n",
       " [8, 8, 19, 27],\n",
       " [8, 8, 19, 27, 16, 12, 21],\n",
       " [8, 8, 19, 27, 16, 21, 28, 26],\n",
       " [8, 8, 19, 27, 17, 12],\n",
       " [8, 8, 19, 27, 26, 17, 12],\n",
       " [8, 8, 19, 32, 8],\n",
       " [8, 8, 19, 32, 8, 15],\n",
       " [8, 8, 19, 32, 8, 21],\n",
       " [8, 8, 19, 32, 10, 16, 8],\n",
       " [8, 8, 19, 32, 15, 8],\n",
       " [8, 8, 19, 32, 16, 8],\n",
       " [8, 8, 19, 32, 16, 8, 15],\n",
       " [8, 8, 19, 32, 21, 8],\n",
       " [8, 8, 19, 32, 26, 16, 8],\n",
       " [8, 8, 19, 32, 26, 26, 8],\n",
       " [8, 8, 19, 32, 29, 16, 8],\n",
       " [8, 8, 20, 8, 16, 25, 8],\n",
       " [8, 8, 20, 8, 21],\n",
       " [8, 8, 20, 8, 21, 8, 15],\n",
       " [8, 8, 20, 8, 21, 11, 8],\n",
       " [8, 8, 20, 8, 21, 12, 12],\n",
       " [8, 8, 20, 8, 21, 16],\n",
       " [8, 8, 20, 8, 25],\n",
       " [8, 8, 20, 8, 25, 16],\n",
       " [8, 8, 20, 8, 25, 16, 22, 21],\n",
       " [8, 8, 20, 8, 32, 8],\n",
       " [8, 8, 20, 9, 12, 25],\n",
       " [8, 8, 20, 12, 21, 8],\n",
       " [8, 8, 20, 12, 21, 8, 15],\n",
       " [8, 8, 20, 12, 25],\n",
       " [8, 8, 20, 16, 8],\n",
       " [8, 8, 20, 16, 19],\n",
       " [8, 8, 20, 16, 19, 8, 15],\n",
       " [8, 8, 20, 16, 21],\n",
       " [8, 8, 20, 16, 21, 8],\n",
       " [8, 8, 20, 16, 21, 8, 15],\n",
       " [8, 8, 20, 16, 25],\n",
       " [8, 8, 20, 16, 25, 8],\n",
       " [8, 8, 20, 16, 25, 8, 15],\n",
       " [8, 8, 20, 16, 32, 8],\n",
       " [8, 8, 20, 16, 32, 8, 15],\n",
       " [8, 8, 20, 21, 8],\n",
       " [8, 8, 20, 21, 8, 15],\n",
       " [8, 8, 20, 22, 21, 16],\n",
       " [8, 8, 20, 22, 25, 8],\n",
       " [8, 8, 20, 22, 25, 8, 15],\n",
       " [8, 8, 20, 22, 25, 16],\n",
       " [8, 8, 20, 32, 8],\n",
       " [8, 8, 20, 32, 8, 15],\n",
       " [8, 8, 21, 8],\n",
       " [8, 8, 21, 8, 21, 11],\n",
       " [8, 8, 21, 8, 29],\n",
       " [8, 8, 21, 8, 32],\n",
       " [8, 8, 21, 8, 32, 8],\n",
       " [8, 8, 21, 8, 32, 8, 15],\n",
       " [8, 8, 21, 10, 15, 8, 19],\n",
       " [8, 8, 21, 16, 8],\n",
       " [8, 8, 21, 16, 8, 15],\n",
       " [8, 8, 21, 16, 17, 8, 15],\n",
       " [8, 8, 21, 16, 18],\n",
       " [8, 8, 21, 16, 18, 8],\n",
       " [8, 8, 21, 16, 26],\n",
       " [8, 8, 21, 16, 26, 8, 15],\n",
       " [8, 8, 21, 16, 26, 15, 8],\n",
       " [8, 8, 21, 16, 32, 8],\n",
       " [8, 8, 21, 16, 32, 8, 15],\n",
       " [8, 8, 21, 16, 32, 19, 8, 15],\n",
       " [8, 8, 21, 26, 15],\n",
       " [8, 8, 21, 26, 15, 16],\n",
       " [8, 8, 21, 26, 28],\n",
       " [8, 8, 21, 27],\n",
       " [8, 8, 21, 28, 22, 19, 28, 30, 8],\n",
       " [8, 8, 21, 29, 16],\n",
       " [8, 8, 21, 32, 8],\n",
       " [8, 8, 21, 32, 8, 15],\n",
       " [8, 8, 21, 32, 19, 8],\n",
       " [8, 8, 23, 12, 19, 16],\n",
       " [8, 8, 23, 22],\n",
       " [8, 8, 23, 23, 22],\n",
       " [8, 8, 23, 25, 16],\n",
       " [8, 8, 24, 16, 9],\n",
       " [8, 8, 24, 16, 19],\n",
       " [8, 8, 25, 8],\n",
       " [8, 8, 25, 8, 9, 12, 19, 19, 8],\n",
       " [8, 8, 25, 8, 9, 15],\n",
       " [8, 8, 25, 8, 9, 15, 16],\n",
       " [8, 8, 25, 8, 9, 16],\n",
       " [8, 8, 25, 8, 11, 15, 8, 21, 8],\n",
       " [8, 8, 25, 8, 11, 15, 32],\n",
       " [8, 8, 25, 8, 11, 15, 32, 8],\n",
       " [8, 8, 25, 8, 12],\n",
       " [8, 8, 25, 8, 13],\n",
       " [8, 8, 25, 8, 15],\n",
       " [8, 8, 25, 8, 16, 33],\n",
       " [8, 8, 25, 8, 19, 32, 21],\n",
       " [8, 8, 25, 8, 19, 32, 21, 21],\n",
       " [8, 8, 25, 8, 21],\n",
       " [8, 8, 25, 8, 21, 16],\n",
       " [8, 8, 25, 8, 21, 32, 8, 21],\n",
       " [8, 8, 25, 8, 22, 21],\n",
       " [8, 8, 25, 8, 27, 16],\n",
       " [8, 8, 25, 8, 27, 25, 16, 18, 8],\n",
       " [8, 8, 25, 8, 29],\n",
       " [8, 8, 25, 8, 29, 16],\n",
       " [8, 8, 25, 8, 29, 17, 16, 27],\n",
       " [8, 8, 25, 8, 29, 25, 12, 11, 11, 32],\n",
       " [8, 8, 25, 8, 32, 8],\n",
       " [8, 8, 25, 11],\n",
       " [8, 8, 25, 11, 15, 21, 8],\n",
       " [8, 8, 25, 12],\n",
       " [8, 8, 25, 12, 21],\n",
       " [8, 8, 25, 12, 21, 27],\n",
       " [8, 8, 25, 12, 22, 21],\n",
       " [8, 8, 25, 12, 22, 21, 8],\n",
       " [8, 8, 25, 12, 33],\n",
       " [8, 8, 25, 16],\n",
       " [8, 8, 25, 16, 8],\n",
       " [8, 8, 25, 16, 8, 15],\n",
       " [8, 8, 25, 16, 8, 21],\n",
       " [8, 8, 25, 16, 8, 21, 8],\n",
       " [8, 8, 25, 16, 8, 21, 21, 8],\n",
       " [8, 8, 25, 16, 9],\n",
       " [8, 8, 25, 16, 10],\n",
       " [8, 8, 25, 16, 10, 8],\n",
       " [8, 8, 25, 16, 10, 18],\n",
       " [8, 8, 25, 16, 12],\n",
       " [8, 8, 25, 16, 12, 19],\n",
       " [8, 8, 25, 16, 12, 19, 19, 8],\n",
       " [8, 8, 25, 16, 12, 19, 19, 12],\n",
       " [8, 8, 25, 16, 12, 21],\n",
       " [8, 8, 25, 16, 13],\n",
       " [8, 8, 25, 16, 13, 8, 15],\n",
       " [8, 8, 25, 16, 18],\n",
       " [8, 8, 25, 16, 18, 8],\n",
       " [8, 8, 25, 16, 18, 12, 27, 15],\n",
       " [8, 8, 25, 16, 19, 32, 21],\n",
       " [8, 8, 25, 16, 19, 32, 21, 21],\n",
       " [8, 8, 25, 16, 21],\n",
       " [8, 8, 25, 16, 21, 16],\n",
       " [8, 8, 25, 16, 22, 21],\n",
       " [8, 8, 25, 16, 22, 21, 8],\n",
       " [8, 8, 25, 16, 22, 21, 21, 8],\n",
       " [8, 8, 25, 16, 26],\n",
       " [8, 8, 25, 16, 26, 15],\n",
       " [8, 8, 25, 16, 27],\n",
       " [8, 8, 25, 16, 29],\n",
       " [8, 8, 25, 16, 32, 8],\n",
       " [8, 8, 25, 16, 32, 8, 15],\n",
       " [8, 8, 25, 16, 32, 8, 21],\n",
       " [8, 8, 25, 16, 32, 8, 21, 8],\n",
       " [8, 8, 25, 16, 32, 8, 21, 21, 8],\n",
       " [8, 8, 25, 16, 32, 22, 21, 8],\n",
       " [8, 8, 25, 16, 32, 22, 21, 21, 8],\n",
       " [8, 8, 25, 16, 33],\n",
       " [8, 8, 25, 17, 8, 21],\n",
       " [8, 8, 25, 17, 8, 29],\n",
       " [8, 8, 25, 17, 28],\n",
       " [8, 8, 25, 17, 28, 21],\n",
       " [8, 8, 25, 19, 12, 32, 3, 25, 8, 32],\n",
       " [8, 8, 25, 19, 22],\n",
       " [8, 8, 25, 20, 8, 8, 21],\n",
       " [8, 8, 25, 21],\n",
       " [8, 8, 25, 21, 8],\n",
       " [8, 8, 25, 21, 8, 29],\n",
       " [8, 8, 25, 21, 8, 29, 16],\n",
       " [8, 8, 25, 21, 12],\n",
       " [8, 8, 25, 21, 16],\n",
       " [8, 8, 25, 21, 22],\n",
       " [8, 8, 25, 21, 22, 28, 11],\n",
       " [8, 8, 25, 21, 22, 28, 27],\n",
       " [8, 8, 25, 22],\n",
       " [8, 8, 25, 22, 15],\n",
       " [8, 8, 25, 22, 15, 8, 21],\n",
       " [8, 8, 25, 22, 15, 16],\n",
       " [8, 8, 25, 22, 19, 32, 21],\n",
       " [8, 8, 25, 22, 21],\n",
       " [8, 8, 25, 22, 21, 3, 17, 8, 20, 12, 26],\n",
       " [8, 8, 25, 22, 21, 3, 17, 8, 32],\n",
       " [8, 8, 25, 22, 21, 3, 17, 22, 15, 21],\n",
       " [8, 8, 25, 22, 21, 3, 19, 12, 12],\n",
       " [8, 8, 25, 22, 21, 3, 20, 8, 27, 27, 15, 12, 30],\n",
       " [8, 8, 25, 22, 21, 8],\n",
       " [8, 8, 25, 22, 21, 8, 12],\n",
       " [8, 8, 25, 22, 21, 8, 25, 27, 15, 28, 25],\n",
       " [8, 8, 25, 22, 21, 11, 8],\n",
       " [8, 8, 25, 22, 21, 11, 12, 12, 23],\n",
       " [8, 8, 25, 22, 21, 12, 27, 27, 12],\n",
       " [8, 8, 25, 22, 21, 16, 26, 15, 8],\n",
       " [8, 8, 25, 22, 21, 17, 8, 10, 22, 9],\n",
       " [8, 8, 25, 22, 21, 17, 8, 20, 12, 26],\n",
       " [8, 8, 25, 22, 21, 17, 16, 27],\n",
       " [8, 8, 25, 22, 21, 17, 22, 15, 21],\n",
       " [8, 8, 25, 22, 21, 17, 22, 26, 12, 23, 15],\n",
       " [8, 8, 25, 22, 21, 17, 22, 26, 15],\n",
       " [8, 8, 25, 22, 21, 17, 22, 26, 15, 28, 8],\n",
       " [8, 8, 25, 22, 21, 19, 12, 12],\n",
       " [8, 8, 25, 22, 21, 20, 16, 10, 15, 8, 12, 19],\n",
       " [8, 8, 25, 22, 21, 21],\n",
       " [8, 8, 25, 22, 21, 26],\n",
       " [8, 8, 25, 22, 21, 26, 22, 21],\n",
       " [8, 8, 25, 22, 21, 29, 12, 12, 25],\n",
       " [8, 8, 25, 22, 22, 21],\n",
       " [8, 8, 25, 22, 22, 26, 15],\n",
       " [8, 8, 25, 25, 8, 21],\n",
       " [8, 8, 25, 25, 12],\n",
       " [8, 8, 25, 25, 12, 21],\n",
       " [8, 8, 25, 25, 22, 21],\n",
       " [8, 8, 25, 25, 32, 21],\n",
       " [8, 8, 25, 26, 15],\n",
       " [8, 8, 25, 26, 15, 16],\n",
       " [8, 8, 25, 26, 15, 16, 32, 8],\n",
       " [8, 8, 25, 27],\n",
       " [8, 8, 25, 27, 15, 16],\n",
       " [8, 8, 25, 27, 16],\n",
       " [8, 8, 25, 28, 15, 16],\n",
       " [8, 8, 25, 28, 21],\n",
       " [8, 8, 25, 28, 21, 32, 8],\n",
       " [8, 8, 25, 28, 26, 8, 21],\n",
       " [8, 8, 25, 28, 26, 15],\n",
       " [8, 8, 25, 28, 26, 15, 16],\n",
       " [8, 8, 25, 28, 26, 15, 25, 12, 11, 11, 32],\n",
       " [8, 8, 25, 29],\n",
       " [8, 8, 25, 29, 16],\n",
       " [8, 8, 25, 29, 16, 18],\n",
       " [8, 8, 25, 29, 16, 21],\n",
       " [8, 8, 25, 32],\n",
       " [8, 8, 25, 32, 8],\n",
       " [8, 8, 25, 32, 8, 15],\n",
       " [8, 8, 25, 32, 8, 15, 16],\n",
       " [8, 8, 25, 32, 8, 21],\n",
       " [8, 8, 25, 32, 8, 21, 8],\n",
       " [8, 8, 25, 32, 8, 21, 21, 8],\n",
       " [8, 8, 25, 32, 8, 26, 15],\n",
       " [8, 8, 25, 32, 8, 29],\n",
       " [8, 8, 25, 32, 19, 8, 21],\n",
       " [8, 8, 25, 32, 21],\n",
       " [8, 8, 25, 32, 21, 3, 17, 22, 15, 21],\n",
       " [8, 8, 25, 32, 21, 3, 23, 8, 28, 19],\n",
       " [8, 8, 25, 32, 21, 21],\n",
       " [8, 8, 25, 32, 22, 21],\n",
       " [8, 8, 25, 32, 22, 21, 8],\n",
       " [8, 8, 25, 33, 8],\n",
       " [8, 8, 25, 33, 16, 26, 15],\n",
       " [8, 8, 25, 33, 22],\n",
       " [8, 8, 25, 33, 22, 22],\n",
       " [8, 8, 25, 33, 28],\n",
       " [8, 8, 25, 54, 21],\n",
       " [8, 8, 26, 12],\n",
       " [8, 8, 26, 12, 12, 20],\n",
       " [8, 8, 26, 12, 25],\n",
       " [8, 8, 26, 15, 8],\n",
       " [8, 8, 26, 15, 8, 21, 8],\n",
       " [8, 8, 26, 15, 8, 32],\n",
       " [8, 8, 26, 15, 11, 22, 21],\n",
       " [8, 8, 26, 15, 16],\n",
       " [8, 8, 26, 15, 16, 8],\n",
       " [8, 8, 26, 15, 16, 13],\n",
       " [8, 8, 26, 15, 16, 18],\n",
       " [8, 8, 26, 15, 16, 18, 8],\n",
       " [8, 8, 26, 15, 16, 19, 11],\n",
       " [8, 8, 26, 15, 16, 21, 16],\n",
       " [8, 8, 26, 15, 16, 25],\n",
       " [8, 8, 26, 15, 16, 25, 32, 8],\n",
       " [8, 8, 26, 15, 16, 26],\n",
       " [8, 8, 26, 15, 16, 26, 15],\n",
       " [8, 8, 26, 15, 16, 27, 8],\n",
       " [8, 8, 26, 15, 16, 32, 8],\n",
       " [8, 8, 26, 15, 16, 32, 8, 21, 8],\n",
       " [8, 8, 26, 15, 18, 8],\n",
       " [8, 8, 26, 15, 20, 8],\n",
       " [8, 8, 26, 15, 20, 8, 21],\n",
       " [8, 8, 26, 15, 21, 8],\n",
       " [8, 8, 26, 15, 21, 16],\n",
       " [8, 8, 26, 15, 25, 8, 32],\n",
       " [8, 8, 26, 15, 25, 16, 27, 8],\n",
       " [8, 8, 26, 15, 25, 16, 27, 15],\n",
       " [8, 8, 26, 15, 25, 16, 27, 15, 8],\n",
       " [8, 8, 26, 15, 25, 16, 32, 8],\n",
       " [8, 8, 26, 15, 28],\n",
       " [8, 8, 26, 15, 28, 27, 22, 26, 15],\n",
       " [8, 8, 26, 15, 29, 16],\n",
       " [8, 8, 26, 16, 8],\n",
       " [8, 8, 26, 16, 8, 15],\n",
       " [8, 8, 26, 16, 13],\n",
       " [8, 8, 26, 16, 20],\n",
       " [8, 8, 26, 16, 21],\n",
       " [8, 8, 26, 16, 25],\n",
       " [8, 8, 26, 16, 32, 8],\n",
       " [8, 8, 26, 16, 32, 8, 15],\n",
       " [8, 8, 26, 20, 8],\n",
       " [8, 8, 26, 20, 16, 21],\n",
       " [8, 8, 26, 22, 21],\n",
       " [8, 8, 26, 25],\n",
       " [8, 8, 26, 27, 15, 8],\n",
       " [8, 8, 26, 27, 22],\n",
       " [8, 8, 26, 27, 22, 21],\n",
       " [8, 8, 26, 28],\n",
       " [8, 8, 27],\n",
       " [8, 8, 27, 8, 20, 16],\n",
       " [8, 8, 27, 15, 8, 21],\n",
       " [8, 8, 27, 15, 8, 29, 8, 21],\n",
       " [8, 8, 27, 15, 16, 26, 15],\n",
       " [8, 8, 27, 15, 25, 12, 32],\n",
       " [8, 8, 27, 15, 32, 21],\n",
       " [8, 8, 27, 16, 13],\n",
       " [8, 8, 27, 16, 13, 8],\n",
       " [8, 8, 27, 16, 18, 8],\n",
       " [8, 8, 27, 16, 18, 8, 15],\n",
       " [8, 8, 27, 16, 18, 28, 21],\n",
       " [8, 8, 27, 16, 24, 8],\n",
       " [8, 8, 27, 16, 24, 8, 15],\n",
       " [8, 8, 27, 16, 26, 15],\n",
       " [8, 8, 27, 22, 26],\n",
       " [8, 8, 27, 25, 12, 32, 8],\n",
       " [8, 8, 27, 27, 22],\n",
       " [8, 8, 27, 28],\n",
       " [8, 8, 29, 8],\n",
       " [8, 8, 29, 8, 3, 20, 8, 32],\n",
       " [8, 8, 29, 8, 15],\n",
       " [8, 8, 29, 8, 21],\n",
       " [8, 8, 29, 8, 26, 15],\n",
       " [8, 8, 29, 12],\n",
       " [8, 8, 29, 12, 21],\n",
       " [8, 8, 29, 16],\n",
       " [8, 8, 29, 16, 21],\n",
       " [8, 8, 29, 16, 22, 21],\n",
       " [8, 8, 29, 16, 25],\n",
       " [8, 8, 29, 16, 26, 15],\n",
       " [8, 8, 29, 21, 16],\n",
       " [8, 8, 29, 22],\n",
       " [8, 8, 29, 32, 8],\n",
       " [8, 8, 29, 32, 8, 21],\n",
       " [8, 8, 29, 32, 21],\n",
       " [8, 8, 32, 8],\n",
       " [8, 8, 32, 8, 8, 21],\n",
       " [8, 8, 32, 8, 15],\n",
       " [8, 8, 32, 8, 20],\n",
       " [8, 8, 32, 8, 21],\n",
       " [8, 8, 32, 8, 21, 8],\n",
       " [8, 8, 32, 8, 21, 8, 15],\n",
       " [8, 8, 32, 8, 21, 21, 8],\n",
       " [8, 8, 32, 8, 21, 26, 15],\n",
       " [8, 8, 32, 8, 27],\n",
       " [8, 8, 32, 11, 8, 21],\n",
       " [8, 8, 32, 11, 12, 21],\n",
       " [8, 8, 32, 11, 12, 21, 3, 17, 8, 20, 12, 26],\n",
       " [8, 8, 32, 11, 12, 21, 3, 17, 22, 21],\n",
       " [8, 8, 32, 11, 21],\n",
       " [8, 8, 32, 12, 26, 15, 8],\n",
       " [8, 8, 32, 16, 26, 15, 8],\n",
       " [8, 8, 32, 19, 8],\n",
       " [8, 8, 32, 19, 8, 15],\n",
       " [8, 8, 32, 19, 8, 15, 3, 25, 22, 26, 12],\n",
       " [8, 8, 32, 19, 16, 8, 15],\n",
       " [8, 8, 32, 19, 16, 12],\n",
       " [8, 8, 32, 22, 21],\n",
       " [8, 8, 32, 25, 8],\n",
       " [8, 8, 32, 25, 8, 21],\n",
       " [8, 8, 32, 26, 15, 8],\n",
       " [8, 8, 32, 28],\n",
       " [8, 8, 32, 28, 26, 15],\n",
       " [8, 8, 32, 28, 26, 15, 8],\n",
       " [8, 8, 32, 28, 26, 15, 16],\n",
       " [8, 8, 32, 33, 8],\n",
       " [8, 8, 33, 8, 11],\n",
       " [8, 8, 33, 8, 21],\n",
       " [8, 8, 33, 12, 12, 21],\n",
       " [8, 8, 33, 16, 19],\n",
       " [8, 8, 33, 16, 20],\n",
       " [8, 8, 33, 16, 32, 8, 15],\n",
       " [8, 9, 8],\n",
       " [8, 9, 8, 8, 21],\n",
       " [8, 9, 8, 8, 26],\n",
       " [8, 9, 8, 11],\n",
       " [8, 9, 8, 14, 8, 12, 19],\n",
       " [8, 9, 8, 14, 8, 16, 19],\n",
       " [8, 9, 8, 14, 8, 16, 19, 12],\n",
       " [8, 9, 8, 14, 8, 19, 12],\n",
       " [8, 9, 8, 14, 8, 32, 19, 12],\n",
       " [8, 9, 8, 16],\n",
       " [8, 9, 8, 16, 14, 8, 12, 19],\n",
       " [8, 9, 8, 16, 14, 8, 16, 19],\n",
       " [8, 9, 8, 16, 14, 12, 8, 19],\n",
       " [8, 9, 8, 16, 14, 15],\n",
       " [8, 9, 8, 21],\n",
       " [8, 9, 8, 21, 8],\n",
       " [8, 9, 8, 21, 22, 28, 9],\n",
       " [8, 9, 8, 26],\n",
       " [8, 9, 8, 26, 16],\n",
       " [8, 9, 8, 26, 16, 3, 16, 20, 8],\n",
       " [8, 9, 8, 26, 26],\n",
       " [8, 9, 8, 27, 12],\n",
       " [8, 9, 8, 32],\n",
       " [8, 9, 8, 32, 22, 20, 16],\n",
       " [8, 9, 8, 33],\n",
       " [8, 9, 8, 33, 8],\n",
       " [8, 9, 9],\n",
       " [8, 9, 9, 8],\n",
       " [8, 9, 9, 8, 8, 26],\n",
       " [8, 9, 9, 8, 11],\n",
       " [8, 9, 9, 8, 14, 8, 16, 19],\n",
       " [8, 9, 9, 8, 14, 8, 19, 12],\n",
       " [8, 9, 9, 8, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 8, 16, 14, 15],\n",
       " [8, 9, 9, 8, 26],\n",
       " [8, 9, 9, 8, 26, 3, 15, 28, 26, 26, 12, 16, 21],\n",
       " [8, 9, 9, 8, 26, 26],\n",
       " [8, 9, 9, 8, 27, 12],\n",
       " [8, 9, 9, 11, 12, 19, 25, 8, 15, 20, 8, 21, 12],\n",
       " [8, 9, 9, 12],\n",
       " [8, 9, 9, 12, 12],\n",
       " [8, 9, 9, 12, 14, 8, 16, 19],\n",
       " [8, 9, 9, 12, 14, 8, 19, 12],\n",
       " [8, 9, 9, 12, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 12, 16, 14, 15],\n",
       " [8, 9, 9, 12, 25, 14, 12, 25],\n",
       " [8, 9, 9, 12, 32],\n",
       " [8, 9, 9, 12, 32, 3, 19, 12, 16, 14, 15],\n",
       " [8, 9, 9, 12, 32, 3, 19, 22, 28, 16, 26, 12],\n",
       " [8, 9, 9, 12, 32, 14, 8, 16, 19],\n",
       " [8, 9, 9, 12, 32, 14, 8, 19, 12],\n",
       " [8, 9, 9, 12, 32, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 16],\n",
       " [8, 9, 9, 16, 3, 19, 12, 16, 14, 15],\n",
       " [8, 9, 9, 16, 3, 19, 22, 28, 16, 26, 12],\n",
       " [8, 9, 9, 16, 3, 20, 8, 12],\n",
       " [8, 9, 9, 16, 3, 25, 22, 26, 12],\n",
       " [8, 9, 9, 16, 12],\n",
       " [8, 9, 9, 16, 12, 3, 8, 21, 21, 12],\n",
       " [8, 9, 9, 16, 12, 3, 14, 8, 16, 19],\n",
       " [8, 9, 9, 16, 12, 3, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 16, 12, 3, 14, 25, 8, 10, 12],\n",
       " [8, 9, 9, 16, 12, 3, 17],\n",
       " [8, 9, 9, 16, 12, 3, 17, 8, 16],\n",
       " [8, 9, 9, 16, 12, 3, 17, 8, 20, 12, 26],\n",
       " [8, 9, 9, 16, 12, 3, 17, 8, 21, 12],\n",
       " [8, 9, 9, 16, 12, 3, 17, 22],\n",
       " [8, 9, 9, 16, 12, 3, 19, 12, 8],\n",
       " [8, 9, 9, 16, 12, 3, 19, 12, 12],\n",
       " [8, 9, 9, 16, 12, 3, 19, 12, 16],\n",
       " [8, 9, 9, 16, 12, 3, 19, 12, 16, 14, 15],\n",
       " [8, 9, 9, 16, 12, 3, 19, 22, 28, 16, 26, 12],\n",
       " [8, 9, 9, 16, 12, 3, 20, 8, 12],\n",
       " [8, 9, 9, 16, 12, 3, 20, 8, 16],\n",
       " [8, 9, 9, 16, 12, 3, 20, 8, 25, 16, 12],\n",
       " [8, 9, 9, 16, 12, 3, 20, 8, 32],\n",
       " [8, 9, 9, 16, 12, 3, 25, 8, 32, 21, 12],\n",
       " [8, 9, 9, 16, 12, 3, 25, 22, 26, 12],\n",
       " [8, 9, 9, 16, 12, 3, 29, 16, 22, 19, 12, 27],\n",
       " [8, 9, 9, 16, 12, 14, 8, 16, 19],\n",
       " [8, 9, 9, 16, 12, 14, 8, 19, 12],\n",
       " [8, 9, 9, 16, 12, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 16, 12, 19, 12, 16, 14, 15],\n",
       " [8, 9, 9, 16, 12, 19, 22, 28, 16, 26, 12],\n",
       " [8, 9, 9, 16, 14, 8, 12, 19],\n",
       " [8, 9, 9, 16, 14, 8, 16, 19],\n",
       " [8, 9, 9, 16, 14, 8, 16, 19, 12],\n",
       " [8, 9, 9, 16, 14, 8, 19],\n",
       " [8, 9, 9, 16, 14, 8, 19, 12],\n",
       " [8, 9, 9, 16, 14, 8, 32, 19],\n",
       " [8, 9, 9, 16, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 16, 14, 15, 8, 16, 19],\n",
       " [8, 9, 9, 16, 19, 32, 21],\n",
       " [8, 9, 9, 16, 21, 12, 32],\n",
       " [8, 9, 9, 16, 26, 26],\n",
       " [8, 9, 9, 22],\n",
       " [8, 9, 9, 22, 21, 11, 8, 21, 33, 8],\n",
       " [8, 9, 9, 22, 21, 11, 8, 21, 33, 16, 22],\n",
       " [8, 9, 9, 22, 21, 11, 16, 22],\n",
       " [8, 9, 9, 22, 27],\n",
       " [8, 9, 9, 22, 27, 26, 12, 21],\n",
       " [8, 9, 9, 22, 27, 26, 22, 21],\n",
       " [8, 9, 9, 22, 27, 26, 28, 21],\n",
       " [8, 9, 9, 22, 27, 27],\n",
       " [8, 9, 9, 22, 27, 27, 26, 22, 21],\n",
       " [8, 9, 9, 25, 8],\n",
       " [8, 9, 9, 25, 16, 12, 19, 19, 8],\n",
       " [8, 9, 9, 25, 16, 12, 19, 19, 12],\n",
       " [8, 9, 9, 32],\n",
       " [8, 9, 9, 32, 3, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 32, 3, 19, 12, 16, 14, 15],\n",
       " [8, 9, 9, 32, 3, 20, 8, 32],\n",
       " [8, 9, 9, 32, 12],\n",
       " [8, 9, 9, 32, 14, 8, 12, 19],\n",
       " [8, 9, 9, 32, 14, 8, 16, 19],\n",
       " [8, 9, 9, 32, 14, 8, 16, 19, 12],\n",
       " [8, 9, 9, 32, 14, 8, 19, 12],\n",
       " [8, 9, 9, 32, 14, 8, 32, 19],\n",
       " [8, 9, 9, 32, 14, 8, 32, 19, 12],\n",
       " [8, 9, 9, 32, 19, 32, 21, 21],\n",
       " [8, 9, 10, 11, 12],\n",
       " [8, 9, 11],\n",
       " [8, 9, 11, 3, 8, 19, 18, 28, 11, 22, 26],\n",
       " [8, 9, 11, 3, 8, 19, 19, 8, 15],\n",
       " [8, 9, 11, 3, 8, 19, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 3, 28, 19, 20, 22, 12, 12, 21],\n",
       " [8, 9, 11, 8, 19],\n",
       " [8, 9, 11, 8, 19, 8],\n",
       " [8, 9, 11, 8, 19, 8, 15],\n",
       " [8, 9, 11, 8, 19, 15, 8, 16],\n",
       " [8, 9, 11, 8, 19, 18, 15, 8, 19, 24],\n",
       " [8, 9, 11, 8, 19, 19, 8],\n",
       " [8, 9, 11, 8, 19, 19, 8, 15],\n",
       " [8, 9, 11, 8, 19, 20, 8, 19, 8, 18],\n",
       " [8, 9, 11, 8, 19, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 8, 19, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 8, 19, 25, 15, 20, 8, 21],\n",
       " [8, 9, 11, 8, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 8, 26],\n",
       " [8, 9, 11, 12, 19],\n",
       " [8, 9, 11, 12, 19, 3, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 12, 19, 8, 33, 16, 33],\n",
       " [8, 9, 11, 12, 19, 15, 8, 11, 16],\n",
       " [8, 9, 11, 12, 19, 15, 8, 20, 16, 11],\n",
       " [8, 9, 11, 12, 19, 16, 19, 8, 15],\n",
       " [8, 9, 11, 12, 19, 18, 8, 11, 12, 25],\n",
       " [8, 9, 11, 12, 19, 18, 8, 25, 12, 12, 20],\n",
       " [8, 9, 11, 12, 19, 18, 8, 25, 16, 20],\n",
       " [8, 9, 11, 12, 19, 18, 25, 16, 20],\n",
       " [8, 9, 11, 12, 19, 19, 8],\n",
       " [8, 9, 11, 12, 19, 19, 8, 15],\n",
       " [8, 9, 11, 12, 19, 20, 8, 11, 17, 16, 11],\n",
       " [8, 9, 11, 12, 19, 20, 8, 14, 12, 12, 11],\n",
       " [8, 9, 11, 12, 19, 20, 8, 19, 12, 18],\n",
       " [8, 9, 11, 12, 19, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 12, 19, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 12, 19, 25, 8, 15, 20, 8, 21, 12],\n",
       " [8, 9, 11, 12, 19, 25, 8, 28, 22, 13],\n",
       " [8, 9, 11, 12, 19, 25, 15, 20, 8, 21],\n",
       " [8, 9, 11, 12, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 12, 25, 8, 15, 20, 8, 21, 12],\n",
       " [8, 9, 11, 12, 25, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 12, 25, 25, 8, 15, 20, 8, 21, 12],\n",
       " [8, 9, 11, 12, 25, 25, 8, 22, 28, 13],\n",
       " [8, 9, 11, 12, 26, 19, 8, 20],\n",
       " [8, 9, 11, 16],\n",
       " [8, 9, 11, 16, 8],\n",
       " [8, 9, 11, 16, 8, 26],\n",
       " [8, 9, 11, 16, 8, 26, 16, 26],\n",
       " [8, 9, 11, 16, 8, 33, 16, 33],\n",
       " [8, 9, 11, 16, 12, 19],\n",
       " [8, 9, 11, 16, 13, 8, 27, 8, 15],\n",
       " [8, 9, 11, 16, 15, 8, 13, 16, 11],\n",
       " [8, 9, 11, 16, 15, 8, 18, 16, 20],\n",
       " [8, 9, 11, 16, 15, 8, 18, 16, 21],\n",
       " [8, 9, 11, 16, 15, 8, 20, 16, 11],\n",
       " [8, 9, 11, 16, 17, 8],\n",
       " [8, 9, 11, 16, 17, 8, 9, 8, 25],\n",
       " [8, 9, 11, 16, 18, 8, 11, 16, 25],\n",
       " [8, 9, 11, 16, 18, 8, 25, 16, 20],\n",
       " [8, 9, 11, 16, 18, 8, 25, 16, 21],\n",
       " [8, 9, 11, 16, 18, 15, 8, 19, 16, 24],\n",
       " [8, 9, 11, 16, 19, 8, 11, 16, 13],\n",
       " [8, 9, 11, 16, 19, 8, 15, 16],\n",
       " [8, 9, 11, 16, 19, 19, 8, 15, 16],\n",
       " [8, 9, 11, 16, 20, 8, 17, 16, 11],\n",
       " [8, 9, 11, 16, 20, 8, 17, 16, 16, 11],\n",
       " [8, 9, 11, 16, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 16, 21, 8, 17, 16, 9],\n",
       " [8, 9, 11, 16, 21, 8, 26, 16, 25],\n",
       " [8, 9, 11, 16, 24, 8, 21, 16],\n",
       " [8, 9, 11, 16, 25, 8, 15, 16, 16, 20],\n",
       " [8, 9, 11, 16, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 16, 25, 8, 15, 16, 21],\n",
       " [8, 9, 11, 16, 25, 8, 15, 20, 8, 8, 21],\n",
       " [8, 9, 11, 16, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 16, 25, 8, 26, 15, 16, 11],\n",
       " [8, 9, 11, 16, 25, 8, 31, 20, 8, 21],\n",
       " [8, 9, 11, 16, 25, 8, 33, 8, 24],\n",
       " [8, 9, 11, 16, 25, 16, 26, 8, 24],\n",
       " [8, 9, 11, 16, 25, 16, 33, 8, 18],\n",
       " [8, 9, 11, 16, 25, 16, 33, 8, 24],\n",
       " [8, 9, 11, 16, 26, 8, 19, 8, 20],\n",
       " [8, 9, 11, 16, 26, 8, 19, 8, 21],\n",
       " [8, 9, 11, 16, 26, 8, 20, 8, 11],\n",
       " [8, 9, 11, 16, 26, 15, 8, 18, 28, 25],\n",
       " [8, 9, 11, 16, 30, 8, 15, 8, 9],\n",
       " [8, 9, 11, 16, 30, 8, 15, 16, 11],\n",
       " [8, 9, 11, 16, 30, 8, 19, 16],\n",
       " [8, 9, 11, 21],\n",
       " [8, 9, 11, 22],\n",
       " [8, 9, 11, 22, 21],\n",
       " [8, 9, 11, 22, 22, 19],\n",
       " [8, 9, 11, 22, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 22, 25, 8, 26, 26, 22, 28, 19],\n",
       " [8, 9, 11, 22, 28],\n",
       " [8, 9, 11, 22, 28, 8, 19, 19, 8, 15],\n",
       " [8, 9, 11, 22, 28, 19],\n",
       " [8, 9, 11, 22, 28, 19, 8, 32, 12],\n",
       " [8, 9, 11, 22, 28, 19, 8, 33, 16, 33],\n",
       " [8, 9, 11, 22, 28, 19, 16, 12],\n",
       " [8, 9, 11, 22, 28, 19, 19, 8, 15],\n",
       " [8, 9, 11, 22, 28, 19, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 22, 28, 19, 21, 22, 28, 25],\n",
       " [8, 9, 11, 22, 28, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 22, 28, 25, 8, 15, 20, 8, 21, 12],\n",
       " [8, 9, 11, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 25, 12, 30],\n",
       " [8, 9, 11, 25, 16, 12, 19],\n",
       " [8, 9, 11, 28],\n",
       " [8, 9, 11, 28, 8, 19],\n",
       " [8, 9, 11, 28, 8, 19, 12, 12, 20],\n",
       " [8, 9, 11, 28, 8, 19, 19, 8, 15],\n",
       " [8, 9, 11, 28, 8, 19, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 28, 12, 19],\n",
       " [8, 9, 11, 28, 15],\n",
       " [8, 9, 11, 28, 19],\n",
       " [8, 9, 11, 28, 19, 0, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 28, 19, 3],\n",
       " [8, 9, 11, 28, 19, 3, 8, 15, 8, 11],\n",
       " [8, 9, 11, 28, 19, 3, 8, 19, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 3, 8, 33, 12, 12, 33],\n",
       " [8, 9, 11, 28, 19, 3, 8, 33, 16, 33],\n",
       " [8, 9, 11, 28, 19, 3, 9, 8, 8, 26, 16, 27],\n",
       " [8, 9, 11, 28, 19, 3, 9, 8, 26, 16, 27],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 8, 11, 16],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 11, 16],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 13, 16, 33],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 18, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 18, 16, 20],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 21, 21, 8, 21],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 24, 24],\n",
       " [8, 9, 11, 28, 19, 3, 15, 8, 26, 12, 12, 9],\n",
       " [8, 9, 11, 28, 19, 3, 17, 8, 9, 9, 8, 25],\n",
       " [8, 9, 11, 28, 19, 3, 18, 8, 25, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 3, 18, 8, 25, 16, 20],\n",
       " [8, 9, 11, 28, 19, 3, 18, 15, 8, 19, 16, 24],\n",
       " [8, 9, 11, 28, 19, 3, 19, 8, 27, 12, 12, 13],\n",
       " [8, 9, 11, 28, 19, 3, 20, 8, 17, 12, 12, 11],\n",
       " [8, 9, 11, 28, 19, 3, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 28, 19, 3, 20, 8, 27, 12, 12, 21],\n",
       " [8, 9, 11, 28, 19, 3, 20, 28, 16, 33],\n",
       " [8, 9, 11, 28, 19, 3, 20, 28, 16, 33, 33],\n",
       " [8, 9, 11, 28, 19, 3, 21, 8, 13, 16],\n",
       " [8, 9, 11, 28, 19, 3, 21, 8, 26, 16, 25],\n",
       " [8, 9, 11, 28, 19, 3, 24, 8, 8, 11, 16, 25],\n",
       " [8, 9, 11, 28, 19, 3, 24, 8, 32, 32, 28, 20],\n",
       " [8, 9, 11, 28, 19, 3, 24, 28, 11, 11, 28, 26],\n",
       " [8, 9, 11, 28, 19, 3, 25, 8, 13, 8, 32],\n",
       " [8, 9, 11, 28, 19, 3, 25, 8, 15, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 3, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 28, 19, 3, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 3, 25, 8, 24, 16, 9],\n",
       " [8, 9, 11, 28, 19, 3, 25, 12, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 3, 26, 8, 20, 8, 11],\n",
       " [8, 9, 11, 28, 19, 3, 26, 8, 20, 12, 12],\n",
       " [8, 9, 11, 28, 19, 3, 26, 8, 20, 16],\n",
       " [8, 9, 11, 28, 19, 3, 26, 15, 8, 13, 16],\n",
       " [8, 9, 11, 28, 19, 3, 30, 8, 15, 8, 8, 9],\n",
       " [8, 9, 11, 28, 19, 3, 30, 8, 15, 15, 8, 9],\n",
       " [8, 9, 11, 28, 19, 8],\n",
       " [8, 9, 11, 28, 19, 8, 8, 15, 16],\n",
       " [8, 9, 11, 28, 19, 8, 15],\n",
       " [8, 9, 11, 28, 19, 8, 15, 8, 11],\n",
       " [8, 9, 11, 28, 19, 8, 15, 16],\n",
       " [8, 9, 11, 28, 19, 8, 16],\n",
       " [8, 9, 11, 28, 19, 8, 19, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 8, 20, 12, 12, 25],\n",
       " [8, 9, 11, 28, 19, 8, 32, 12],\n",
       " [8, 9, 11, 28, 19, 8, 33, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 8, 33, 12, 12, 33],\n",
       " [8, 9, 11, 28, 19, 8, 33, 16, 20],\n",
       " [8, 9, 11, 28, 19, 8, 33, 16, 26],\n",
       " [8, 9, 11, 28, 19, 8, 33, 16, 33],\n",
       " [8, 9, 11, 28, 19, 9, 8, 18, 16],\n",
       " [8, 9, 11, 28, 19, 9, 8, 25, 16],\n",
       " [8, 9, 11, 28, 19, 9, 8, 26, 16, 27],\n",
       " [8, 9, 11, 28, 19, 10, 8, 9, 9, 8, 25],\n",
       " [8, 9, 11, 28, 19, 12],\n",
       " [8, 9, 11, 28, 19, 12, 19, 8, 15],\n",
       " [8, 9, 11, 28, 19, 13, 8, 27, 8, 15],\n",
       " [8, 9, 11, 28, 19, 13, 8, 27, 27, 8, 15],\n",
       " [8, 9, 11, 28, 19, 13, 8, 30, 8, 33],\n",
       " [8, 9, 11, 28, 19, 14, 15, 8, 21, 16],\n",
       " [8, 9, 11, 28, 19, 15, 8, 8, 11, 16],\n",
       " [8, 9, 11, 28, 19, 15, 8, 11, 16],\n",
       " [8, 9, 11, 28, 19, 15, 8, 18, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 15, 8, 18, 16, 20],\n",
       " [8, 9, 11, 28, 19, 15, 8, 19, 16, 20],\n",
       " [8, 9, 11, 28, 19, 15, 8, 20, 12, 12, 11],\n",
       " [8, 9, 11, 28, 19, 15, 8, 20, 16, 11],\n",
       " [8, 9, 11, 28, 19, 15, 8, 24],\n",
       " [8, 9, 11, 28, 19, 15, 8, 32],\n",
       " [8, 9, 11, 28, 19, 16, 19, 8, 15],\n",
       " [8, 9, 11, 28, 19, 17, 8, 9, 8, 8, 25],\n",
       " [8, 9, 11, 28, 19, 17, 8, 9, 9, 8, 25],\n",
       " [8, 9, 11, 28, 19, 17, 8, 19, 12, 12, 19],\n",
       " [8, 9, 11, 28, 19, 17, 8, 19, 16, 19],\n",
       " [8, 9, 11, 28, 19, 18, 8, 11, 12, 25],\n",
       " [8, 9, 11, 28, 19, 18, 8, 11, 16, 25],\n",
       " [8, 9, 11, 28, 19, 18, 8, 11, 32, 25],\n",
       " [8, 9, 11, 28, 19, 18, 8, 25, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 18, 8, 25, 16, 20],\n",
       " [8, 9, 11, 28, 19, 18, 12, 25, 16, 20],\n",
       " [8, 9, 11, 28, 19, 18, 15, 8, 19, 12, 18],\n",
       " [8, 9, 11, 28, 19, 18, 15, 8, 19, 16, 11],\n",
       " [8, 9, 11, 28, 19, 18, 15, 8, 19, 16, 24],\n",
       " [8, 9, 11, 28, 19, 19],\n",
       " [8, 9, 11, 28, 19, 19, 8],\n",
       " [8, 9, 11, 28, 19, 19, 8, 8, 15],\n",
       " [8, 9, 11, 28, 19, 19, 8, 8, 15, 16],\n",
       " [8, 9, 11, 28, 19, 19, 8, 15],\n",
       " [8, 9, 11, 28, 19, 19, 8, 15, 16],\n",
       " [8, 9, 11, 28, 19, 19, 8, 27, 12, 12, 13],\n",
       " [8, 9, 11, 28, 19, 19, 8, 27, 16, 13],\n",
       " [8, 9, 11, 28, 19, 19, 9, 8, 26, 16, 27],\n",
       " [8, 9, 11, 28, 19, 19, 22, 15],\n",
       " [8, 9, 11, 28, 19, 20, 8, 17, 12, 12, 11],\n",
       " [8, 9, 11, 28, 19, 20, 8, 17, 16, 11],\n",
       " [8, 9, 11, 28, 19, 20, 8, 19, 12, 18],\n",
       " [8, 9, 11, 28, 19, 20, 8, 19, 16, 18],\n",
       " [8, 9, 11, 28, 19, 20, 8, 21, 21, 8, 21],\n",
       " [8, 9, 11, 28, 19, 20, 12, 11, 17, 16, 27],\n",
       " [8, 9, 11, 28, 19, 20, 22, 8, 20, 12, 21],\n",
       " [8, 9, 11, 28, 19, 20, 22, 15, 26, 12, 21],\n",
       " [8, 9, 11, 28, 19, 20, 22, 15, 32, 20, 12, 21],\n",
       " [8, 9, 11, 28, 19, 21, 8, 26, 16, 25],\n",
       " [8, 9, 11, 28, 19, 24, 8, 11, 16, 25],\n",
       " [8, 9, 11, 28, 19, 25, 8, 15, 12, 12, 20],\n",
       " [8, 9, 11, 28, 19, 25, 8, 15, 12, 16, 20],\n",
       " [8, 9, 11, 28, 19, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 28, 19, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 25, 8, 33, 8, 18],\n",
       " [8, 9, 11, 28, 19, 25, 8, 33, 8, 24],\n",
       " [8, 9, 11, 28, 19, 25, 12, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 25, 15, 8, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 25, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 19, 26, 8, 19, 8, 20],\n",
       " [8, 9, 11, 28, 19, 26, 8, 20, 8, 11],\n",
       " [8, 9, 11, 28, 19, 26, 8, 20, 12, 27],\n",
       " [8, 9, 11, 28, 19, 26, 15, 8, 18, 28, 25],\n",
       " [8, 9, 11, 28, 19, 30, 8, 11, 28, 11],\n",
       " [8, 9, 11, 28, 19, 30, 8, 15, 8, 9],\n",
       " [8, 9, 11, 28, 19, 30, 8, 15, 15, 8, 9],\n",
       " [8, 9, 11, 28, 19, 30, 8, 15, 16, 11],\n",
       " [8, 9, 11, 28, 19, 30, 8, 19, 16],\n",
       " [8, 9, 11, 28, 25],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 13, 8, 32],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 13, 12, 15],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 15, 12, 12, 20],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 15, 20, 8, 8, 21],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 25, 3, 25, 8, 26, 15, 12, 12, 11],\n",
       " [8, 9, 11, 28, 25, 3, 25, 12, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 25, 8, 15, 12, 12, 20],\n",
       " [8, 9, 11, 28, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 28, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 25, 8, 15, 20, 22, 21],\n",
       " [8, 9, 11, 28, 25, 25, 8, 15, 12, 12, 20],\n",
       " [8, 9, 11, 28, 25, 25, 8, 15, 16, 20],\n",
       " [8, 9, 11, 28, 25, 25, 8, 15, 20, 8, 8, 21],\n",
       " [8, 9, 11, 28, 25, 25, 8, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 25, 25, 8, 28, 13],\n",
       " [8, 9, 11, 28, 25, 25, 12, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 25, 25, 15, 20, 8, 21],\n",
       " [8, 9, 11, 28, 26],\n",
       " [8, 9, 11, 28, 26, 3, 26, 8, 19, 8, 20],\n",
       " [8, 9, 11, 28, 26, 3, 26, 8, 20, 8, 11],\n",
       " [8, 9, 11, 28, 26, 3, 26, 8, 20, 16],\n",
       " [8, 9, 11, 28, 26, 8, 19, 8, 20],\n",
       " [8, 9, 11, 28, 26, 9, 8, 26, 16, 32, 25],\n",
       " [8, 9, 11, 28, 26, 15, 8, 18, 28, 25],\n",
       " [8, 9, 11, 28, 26, 26, 8, 19, 8, 20],\n",
       " [8, 9, 11, 28, 26, 26, 8, 20, 8, 11],\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [[char2idx[ch] for ch in name] for name in names]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6dfc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"/app/dataset/first_names.json\",\"r\",encoding='utf8') as f:\n",
    "    first_names = json.load(f)\n",
    "\n",
    "with open(\"/app/dataset/last_names.json\",\"r\",encoding='utf8') as f:\n",
    "    last_names = json.load(f)\n",
    "\n",
    "\n",
    "def generate_names(first_names,last_names,count=10000):\n",
    "    return [f\"{f} {l}\" for f,l in zip(\n",
    "    random.choices(first_names,k=count),\n",
    "    random.choices(last_names,k=count)\n",
    "    )]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1004e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_names = generate_names(first_names,last_names,count=10000)\n",
    "len(full_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f5287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sequences):\n",
    "    vocab = sorted(set(\"\".join(sequences)))\n",
    "    char2idx = {ch: idx + 2 for idx, ch in enumerate(vocab)}  # Start from 2\n",
    "    char2idx[\"<PAD>\"] = 0\n",
    "    char2idx[\"<START>\"] = 1\n",
    "    idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37171b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cha,idx = build_vocab(full_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef140295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ' ',\n",
       " 3: \"'\",\n",
       " 4: '-',\n",
       " 5: '/',\n",
       " 6: 'a',\n",
       " 7: 'b',\n",
       " 8: 'c',\n",
       " 9: 'd',\n",
       " 10: 'e',\n",
       " 11: 'f',\n",
       " 12: 'g',\n",
       " 13: 'h',\n",
       " 14: 'i',\n",
       " 15: 'j',\n",
       " 16: 'k',\n",
       " 17: 'l',\n",
       " 18: 'm',\n",
       " 19: 'n',\n",
       " 20: 'o',\n",
       " 21: 'p',\n",
       " 22: 'q',\n",
       " 23: 'r',\n",
       " 24: 's',\n",
       " 25: 't',\n",
       " 26: 'u',\n",
       " 27: 'v',\n",
       " 28: 'w',\n",
       " 29: 'x',\n",
       " 30: 'y',\n",
       " 31: 'z',\n",
       " 32: '\\x9a',\n",
       " 33: 'á',\n",
       " 34: 'â',\n",
       " 35: 'ã',\n",
       " 36: 'ä',\n",
       " 37: 'å',\n",
       " 38: 'æ',\n",
       " 39: 'ç',\n",
       " 40: 'è',\n",
       " 41: 'é',\n",
       " 42: 'ê',\n",
       " 43: 'ë',\n",
       " 44: 'ì',\n",
       " 45: 'í',\n",
       " 46: 'ï',\n",
       " 47: 'ð',\n",
       " 48: 'ñ',\n",
       " 49: 'ó',\n",
       " 50: 'ô',\n",
       " 51: 'õ',\n",
       " 52: 'ö',\n",
       " 53: 'ø',\n",
       " 54: 'ú',\n",
       " 55: 'ü',\n",
       " 56: 'ý',\n",
       " 57: 'þ',\n",
       " 58: 'ā',\n",
       " 59: 'ă',\n",
       " 60: 'ć',\n",
       " 61: 'č',\n",
       " 62: 'đ',\n",
       " 63: 'ė',\n",
       " 64: 'ğ',\n",
       " 65: 'ī',\n",
       " 66: 'ı',\n",
       " 67: 'ļ',\n",
       " 68: 'ł',\n",
       " 69: 'ř',\n",
       " 70: 'ş',\n",
       " 71: 'ţ',\n",
       " 72: 'ž',\n",
       " 0: '<PAD>',\n",
       " 1: '<START>'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fba516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/site-packages (from triton==3.3.1->torch) (65.5.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torch]m20/21\u001b[0m [torch]-cusolver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.18.0 fsspec-2025.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d803a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def prepare_dataset(sequences, char2idx):\n",
    "    X, Y = [], []\n",
    "    for seq in sequences:\n",
    "        ids = [char2idx[\"<START>\"]] + [char2idx[c] for c in seq if c in char2idx]\n",
    "        if len(ids) < 2:\n",
    "            continue\n",
    "        X.append(torch.tensor(ids[:-1]))\n",
    "        Y.append(torch.tensor(ids[1:]))\n",
    "    return pad_sequence(X, batch_first=True), pad_sequence(Y, batch_first=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91174fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = prepare_dataset(full_names, cha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9f45087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e664a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "embedding_dim = 1024\n",
    "hidden_dim = 512\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "vocab_size = len(cha)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "909b9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class StringGEN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=512, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a86bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor,Y_tensor = prepare_dataset(full_names, cha)\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c9a7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StringGEN(vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=cha[\"<PAD>\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad04019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0000\n",
      "Epoch 2/20, Loss: 0.0000\n",
      "Epoch 3/20, Loss: 0.0000\n",
      "Epoch 4/20, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bat_x, bat_y in dataloader:\n",
    "        bat_x, bat_y = bat_x.to(device), bat_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(bat_x)\n",
    "        loss = loss_fn(logits.view(-1, vocab_size), bat_y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()  # Optional if you're using a learning rate scheduler\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model, char2idx, idx2char, max_len=20):\n",
    "    model.eval()\n",
    "    start_id = torch.tensor([[char2idx[\"<START>\"]]], dtype=torch.long).to(device)\n",
    "    hidden = None\n",
    "    input_ids = start_id\n",
    "    output_str = \"\"\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits, hidden = model(input_ids, hidden)  # input_ids: [1,1]\n",
    "        probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # shape: [1,1]\n",
    "        char = idx2char.get(next_id.item(), \"\")\n",
    "        if char == \"<PAD>\":\n",
    "            break\n",
    "        output_str += char\n",
    "        input_ids = next_id  # keep it as [1,1] for next GRU input\n",
    "\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57663911",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GRU: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate_name(model, cha, idx))\n",
      "Cell \u001b[0;32mIn[76], line 9\u001b[0m, in \u001b[0;36mgenerate_name\u001b[0;34m(model, char2idx, idx2char, max_len)\u001b[0m\n\u001b[1;32m      6\u001b[0m output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len):\n\u001b[0;32m----> 9\u001b[0m     logits, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m     next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(probs, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[72], line 10\u001b[0m, in \u001b[0;36mStringGEN.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x)\n\u001b[0;32m---> 10\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, hidden\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1356\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1354\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1358\u001b[0m     )\n\u001b[1;32m   1359\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1360\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: GRU: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "print(generate_name(model, cha, idx))\n",
    "print(generate_name(model, cha, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4fb288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2699824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
