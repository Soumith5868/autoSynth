{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fc00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from .env\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read values\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# Initialize OpenAI-compatible client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(\"Config loaded from .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd7e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /app\n",
      "Files here: ['.dockerignore', '.env', '.git', '.gitignore', '.ipynb_checkpoints', 'config.yaml', 'docker-compose.yaml', 'Dockerfile', 'python', 'README.md', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"Files here:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bdcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"schema_models\", \"/app/python/schema_models.py\")\n",
    "schema_models = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(schema_models)\n",
    "\n",
    "SchemaPrompt = schema_models.SchemaPrompt\n",
    "SchemaObject = schema_models.SchemaObject\n",
    "ColumnSchema = schema_models.ColumnSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b46e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pydantic import ValidationError\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "def test_llm(client):\n",
    "    test = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say hello\"}]\n",
    "    )\n",
    "    print(\"✅ Test LLM response:\", test.choices[0].message.content)\n",
    "\n",
    "\n",
    "class SchemaAgent:\n",
    "    def __init__(self, llm_client: OpenAI):\n",
    "        self.llm = llm_client\n",
    "\n",
    "    def generate_from_prompt(self, schema_prompt: SchemaPrompt) -> SchemaObject:\n",
    "        assert schema_prompt.prompt, \"Prompt is required\"\n",
    "        system_msg = (\n",
    "            \"You are a strict schema generator. Return ONLY a JSON object like:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"columns\\\": [\\n\"\n",
    "            \"    {\\\"name\\\": \\\"age\\\", \\\"type\\\": \\\"int\\\", \\\"min\\\": 0, \\\"max\\\": 120},\\n\"\n",
    "            \"    {\\\"name\\\": \\\"gender\\\", \\\"type\\\": \\\"categorical\\\", \\\"values\\\": [\\\"M\\\", \\\"F\\\"]},\\n\"\n",
    "            \"    {\\\"name\\\": \\\"admission_date\\\", \\\"type\\\": \\\"datetime\\\", \\\"format\\\": \\\"%Y-%m-%d\\\"}\\n\"\n",
    "            \"  ]\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "        user_msg = f\"Use-case: {schema_prompt.use_case}\\nPrompt: {schema_prompt.prompt}\"\n",
    "\n",
    "        response = self.llm.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        text = response.choices[0].message.content\n",
    "        if not text or not text.strip():\n",
    "            raise ValueError(\"❌ Empty response from LLM. Check API key, base URL, or network.\")\n",
    "        print(\"✅ LLM Output:\\n\", text)\n",
    "        if not text or not text.strip():\n",
    "            raise ValueError(\"LLM response is empty or invalid. Check API status or quota.\")\n",
    "\n",
    "        try:\n",
    "            # Try to extract valid JSON from potentially messy output\n",
    "            json_start = text.find('{')\n",
    "            json_end = text.rfind('}') + 1\n",
    "            parsed = json.loads(text[json_start:json_end])\n",
    "            return SchemaObject(use_case=schema_prompt.use_case, **parsed)\n",
    "        except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"❌ LLM output invalid: {e}\")\n",
    "            raise ValueError(f\"LLM returned malformed or invalid schema.\\nRaw output:\\n{text}\")\n",
    "\n",
    "    def generate_from_csv(self, schema_prompt: SchemaPrompt) -> SchemaObject:\n",
    "        assert schema_prompt.csv_path, \"CSV path is required\"\n",
    "        df = pd.read_csv(schema_prompt.csv_path)\n",
    "        cols = []\n",
    "\n",
    "        for col in df.columns:\n",
    "            dtype = df[col].dtype\n",
    "            col_type = \"string\"\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                col_type = \"int\"\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                col_type = \"float\"\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                col_type = \"datetime\"\n",
    "            elif pd.api.types.is_categorical_dtype(dtype) or df[col].nunique() < 10:\n",
    "                col_type = \"categorical\"\n",
    "\n",
    "            col_schema = ColumnSchema(\n",
    "                name=col,\n",
    "                type=col_type,\n",
    "                min=float(df[col].min()) if col_type in [\"int\", \"float\"] else None,\n",
    "                max=float(df[col].max()) if col_type in [\"int\", \"float\"] else None,\n",
    "                values=list(map(str, df[col].dropna().unique())) if col_type == \"categorical\" else None,\n",
    "                format=\"%Y-%m-%d\" if col_type == \"datetime\" else None\n",
    "            )\n",
    "            cols.append(col_schema)\n",
    "\n",
    "        return SchemaObject(use_case=schema_prompt.use_case, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374f1906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Output:\n",
      " ```json\n",
      "{\n",
      "  \"columns\": [\n",
      "    {\"name\": \"age\", \"type\": \"int\", \"min\": 18, \"max\": 65},\n",
      "    {\"name\": \"gender\", \"type\": \"categorical\", \"values\": [\"M\", \"F\"]},\n",
      "    {\"name\": \"role\", \"type\": \"string\"},\n",
      "    {\"name\": \"join_date\", \"type\": \"datetime\", \"format\": \"%Y-%m-%d\"}\n",
      "  ]\n",
      "}\n",
      "```\n",
      "use_case='Employee record generation' columns=[ColumnSchema(name='age', type='int', min=18.0, max=65.0, format=None, values=None), ColumnSchema(name='gender', type='categorical', min=None, max=None, format=None, values=['M', 'F']), ColumnSchema(name='role', type='string', min=None, max=None, format=None, values=None), ColumnSchema(name='join_date', type='datetime', min=None, max=None, format='%Y-%m-%d', values=None)]\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = SchemaPrompt(\n",
    "    use_case=\"Employee record generation\",\n",
    "    prompt=\"Generate a schema for employee records including age (18-65), gender (M/F), role, and join date\"\n",
    ")\n",
    "\n",
    "schema_agent = SchemaAgent(llm_client=client)  # `client` = your DeepSeek OpenAI-compatible instance\n",
    "\n",
    "schema = schema_agent.generate_from_prompt(schema_prompt)\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344e1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ctgan\n",
      "  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/site-packages (from ctgan) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/site-packages (from ctgan) (2.3.0)\n",
      "Collecting torch>=1.13.0 (from ctgan)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.10/site-packages (from ctgan) (4.67.1)\n",
      "Collecting rdt>=1.14.0 (from ctgan)\n",
      "  Downloading rdt-1.17.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.0->ctgan) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->ctgan) (1.17.0)\n",
      "Collecting scipy>=1.9.2 (from rdt>=1.14.0->ctgan)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from rdt>=1.14.0->ctgan)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.10/site-packages (from rdt>=1.14.0->ctgan) (37.3.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.1.0->rdt>=1.14.0->ctgan)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->rdt>=1.14.0->ctgan)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch>=1.13.0->ctgan)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->ctgan) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.13.0->ctgan)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.13.0->ctgan)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->ctgan) (3.1.6)\n",
      "Collecting fsspec (from torch>=1.13.0->ctgan)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.13.0->ctgan)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.13.0->ctgan)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.13.0->ctgan) (65.5.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.13.0->ctgan)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->ctgan) (3.0.2)\n",
      "Downloading ctgan-0.11.0-py3-none-any.whl (24 kB)\n",
      "Downloading rdt-1.17.0-py3-none-any.whl (73 kB)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, threadpoolctl, sympy, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, fsspec, filelock, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, rdt, nvidia-cusolver-cu12, torch, ctgan\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [ctgan]m25/27\u001b[0m [torch]-cusolver-cu12]2]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ctgan-0.11.0 filelock-3.18.0 fsspec-2025.5.1 joblib-1.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 rdt-1.17.0 scikit-learn-1.7.0 scipy-1.15.3 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ctgan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39f1b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from typing import List\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "class CTGANGeneratorAgent:\n",
    "    def __init__(self):\n",
    "        self.faker = Faker()\n",
    "        self.model = CTGAN(epochs=100)\n",
    "        self.generated_categories = {}\n",
    "\n",
    "    def get_dynamic_category(self, col_name: str, generator_fn, max_unique=200):\n",
    "        if col_name not in self.generated_categories:\n",
    "            self.generated_categories[col_name] = list({generator_fn() for _ in range(max_unique)})\n",
    "        return random.choice(self.generated_categories[col_name])\n",
    "    \n",
    "    \n",
    "    def generate_fake_data_from_schema(self, schema: SchemaObject, n=100) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for _ in range(n):\n",
    "            row = {}\n",
    "            for col in schema.columns:\n",
    "                if col.type == \"int\":\n",
    "                    row[col.name] = random.randint(int(col.min or 0), int(col.max or 100))\n",
    "                elif col.type == \"float\":\n",
    "                    row[col.name] = round(random.uniform(col.min or 0.0, col.max or 100.0), 2)\n",
    "                elif col.type == \"categorical\":\n",
    "                    row[col.name] = random.choice(col.values or [\"Unknown\"])\n",
    "                elif col.type == \"datetime\":\n",
    "                    fmt = col.format or \"%Y-%m-%d\"\n",
    "                    row[col.name] = self.faker.date_between(start_date='-5y', end_date='today').strftime(fmt)\n",
    "                elif col.type == \"string\":\n",
    "                    row[col.name] = None\n",
    "                else:\n",
    "                    row[col.name] = None\n",
    "            rows.append(row)\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def fit_ctgan_on_fake_data(self, fake_df: pd.DataFrame, schema: SchemaObject):\n",
    "        cat_cols = [col.name for col in schema.columns if col.type == \"categorical\"]\n",
    "        self.model.fit(fake_df, discrete_columns=cat_cols)\n",
    "\n",
    "    def sample(self, n=100) -> pd.DataFrame:\n",
    "        return self.model.sample(n)\n",
    "\n",
    "    def generate_from_schema(self, schema: SchemaObject, n=100) -> pd.DataFrame:\n",
    "        fake_df = self.generate_fake_data_from_schema(schema, n=100)\n",
    "\n",
    "        valid_types = [\"int\", \"float\", \"categorical\"]\n",
    "        safe_cols = [col.name for col in schema.columns if col.type in valid_types]\n",
    "        fake_df = fake_df[safe_cols]\n",
    "\n",
    "        self.fit_ctgan_on_fake_data(fake_df, schema)\n",
    "        sampled = self.sample(n)\n",
    "        return self.enforce_bounds(sampled, schema)\n",
    "    \n",
    "    def enforce_bounds(self, df: pd.DataFrame, schema: SchemaObject) -> pd.DataFrame:\n",
    "        for col in schema.columns:\n",
    "            if col.type == \"int\":\n",
    "                df[col.name] = df[col.name].clip(lower=col.min or 0, upper=col.max or 100).astype(int)\n",
    "            elif col.type == \"float\":\n",
    "                df[col.name] = df[col.name].clip(lower=col.min or 0.0, upper=col.max or 100.0).astype(float)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414586f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Output:\n",
      " ```json\n",
      "{\n",
      "  \"columns\": [\n",
      "    {\"name\": \"name\", \"type\": \"string\"},\n",
      "    {\"name\": \"place\", \"type\": \"string\"},\n",
      "    {\"name\": \"age\", \"type\": \"int\", \"min\": 18, \"max\": 60},\n",
      "    {\"name\": \"gender\", \"type\": \"categorical\", \"values\": [\"M\", \"F\"]},\n",
      "    {\"name\": \"city\", \"type\": \"string\"},\n",
      "    {\"name\": \"salary\", \"type\": \"int\", \"min\": 30000, \"max\": 150000},\n",
      "    {\"name\": \"join_date\", \"type\": \"datetime\", \"format\": \"%Y-%m-%d\"}\n",
      "  ]\n",
      "}\n",
      "```\n",
      "   age gender  salary\n",
      "0   53      M  150000\n",
      "1   18      M   50966\n",
      "2   38      F   30000\n",
      "3   20      M   30000\n",
      "4   19      M   67520\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "schema_prompt = SchemaPrompt(\n",
    "    use_case=\"Retail customer data\",\n",
    "    prompt=\"Create schema with name,place ,age (18-60), gender (M/F), city, salary (100k-200k), join_date\"\n",
    ")\n",
    "\n",
    "schema = SchemaAgent(llm_client=client).generate_from_prompt(schema_prompt)\n",
    "\n",
    "gen = CTGANGeneratorAgent()\n",
    "df = gen.generate_from_schema(schema, n=5)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c987c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
